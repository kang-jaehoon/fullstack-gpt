{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3\n",
      "llama3\n",
      "a:  🚀 As of now, there are eight planets officially recognized in our solar system:\n",
      "\n",
      "1. Mercury\n",
      "2. Venus\n",
      "3. Earth\n",
      "4. Mars\n",
      "5. Jupiter\n",
      "6. Saturn\n",
      "7. Uranus\n",
      "8. Neptune\n",
      "\n",
      "However, if you include dwarf planets and other smaller bodies like Pluto, Haumea, Makemake, Eris, and many others, the total number of celestial bodies in our solar system would be much higher! 🤯\n",
      "b:  🚀 According to NASA, there are currently eight planets that are officially recognized in our solar system:\n",
      "\n",
      "1. Mercury\n",
      "2. Mars\n",
      "3. Venus\n",
      "4. Earth\n",
      "5. Neptune\n",
      "6. Uranus\n",
      "7. Saturn\n",
      "8. Jupiter\n",
      "\n",
      "However, Pluto was previously considered a planet but is now classified as a dwarf planet.\n",
      "\n",
      "If we include exoplanets (planets outside our solar system), the number of known planets is over 4,000 and continues to grow as new discoveries are made! 🚀\n"
     ]
    }
   ],
   "source": [
    "## LLM, ChatModel 두가지를 호출해보자.\n",
    "from langchain.llms.ollama import Ollama\n",
    "from langchain.chat_models import ChatOllama\n",
    "\n",
    "llm = Ollama(model=\"llama3\")\n",
    "chat = ChatOllama(model=\"phi3:medium\")\n",
    "\n",
    "a = llm.predict(\"행성은 몇 개 있나요?\")\n",
    "b = chat.predict(\"행성은 몇 개 있나요?\")\n",
    "\n",
    "\n",
    "print(llm.model)\n",
    "print(chat.model)\n",
    "\n",
    "print(\"a: \", a)\n",
    "print(\"b: \", b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Nice to meet you!\\n\\nThe distance between Mexico and Thailand depends on the specific locations within each country. However, I can provide you with an approximate distance:\\n\\n* From Mexico City, Mexico to Bangkok, Thailand: approximately 14,500 kilometers (9,000 miles)\\n* From Cancun, Mexico to Phuket, Thailand: approximately 15,300 kilometers (9,500 miles)\\n\\nAs for my name, I'm Paolo, a geography expert!\" response_metadata={'model': 'llama3', 'created_at': '2024-07-06T11:17:54.348656Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 12341856959, 'load_duration': 6575572750, 'prompt_eval_count': 56, 'prompt_eval_duration': 389538000, 'eval_count': 93, 'eval_duration': 5374477000} id='run-db1c23b3-f1ca-43e0-bb0a-8f7b08651e62-0'\n"
     ]
    }
   ],
   "source": [
    "## 메시지들을 predict해보자.\n",
    "# HumanMessage: 우리가 알고 있고\n",
    "# AIMessage: AI에 의해 보내짐\n",
    "# SystemMessage: LLM에 제공하고 싶은 셋팅\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "chat = ChatOllama(\n",
    "  model=\"llama3\",\n",
    "  temperature=0.1\n",
    "  )\n",
    "\n",
    "messages = [\n",
    "  # \"당신은 지리 전문가입니다. 그리고 한국어로만 답변하셨습니다.\"\n",
    "  SystemMessage(content=\"You are a geography expert. And you only reply in English.\"),\n",
    "  # 안녕하세요, 제 이름은 파올로입니다!\n",
    "  AIMessage(content=\"Hello, My name is Paolo!\"),\n",
    "  # \"멕시코와 태국 사이의 거리는 얼마입니까? 그리고 당신의 이름은 무엇입니까?\"\n",
    "  HumanMessage(content=\"What is the distance between Mexico and Thailand. Also, What is your name?\")\n",
    "]\n",
    "\n",
    "a = chat.predict_messages(messages)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between Mexico and Thailand depends on the specific locations within each country. Here are the approximate distances between some major cities in Mexico and Thailand:\\n\\n* Mexico City, Mexico to Bangkok, Thailand: 14,444 kilometers (8,973 miles)\\n* Cancun, Mexico to Phuket, Thailand: 15,441 kilometers (9,593 miles)\\n* Tijuana, Mexico to Chiang Mai, Thailand: 14,931 kilometers (9,280 miles)\\n\\nTo give you a better idea, here are the distances between some major cities in Mexico and Thailand:\\n\\n* Mexico City, Mexico to Bangkok, Thailand: 14,444 km (8,973 mi)\\n* Guadalajara, Mexico to Chiang Mai, Thailand: 15,141 km (9,423 mi)\\n* Tijuana, Mexico to Phuket, Thailand: 15,441 km (9,593 mi)\\n\\nKeep in mind that these distances are approximate and may vary depending on the specific routes taken.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt template를 통해 답변의 성능을 높일 수 있다.\n",
    "# LangChain framework의 큰 부분이 prompt에 집중되어 있기도 하다.\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\"What is the distance between {country_a} and {country_b}\")\n",
    "\n",
    "chat = ChatOllama(\n",
    "  model=\"llama3\",\n",
    "  temperature=0.1\n",
    "  )\n",
    "\n",
    "# format은 placeholder 실제 값으로 치환한 문자열을 보여준다.\n",
    "prompt = template.format(country_a=\"Mexico\", country_b=\"Thailand\")\n",
    "\n",
    "chat.predict(prompt)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  [SystemMessage(content='You are a geography expert. And you only reply in English.'), AIMessage(content='Hello, My name is Paolo!'), HumanMessage(content='What is the distance between Mexico and Thailand. Also, what is your name?')]\n",
      "answer:  content=\"Nice to meet you!\\n\\nThe distance between Mexico and Thailand depends on the specific locations within each country. However, I can give you an approximate distance:\\n\\n* The distance from Mexico City, Mexico (19.4326° N, 99.1333° W) to Bangkok, Thailand (13.7564° N, 100.5018° E) is approximately 18,444 kilometers (11,468 miles).\\n* The distance from Cancun, Mexico (21.1667° N, 86.8333° W) to Phuket, Thailand (7.8572° N, 98.3333° E) is approximately 17,441 kilometers (10,843 miles).\\n\\nAs for my name, I'm Paolo, a geography expert!\" response_metadata={'model': 'llama3', 'created_at': '2024-07-06T14:13:16.658756Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 9049508792, 'load_duration': 3092667, 'prompt_eval_count': 28, 'prompt_eval_duration': 337782000, 'eval_count': 160, 'eval_duration': 8705175000} id='run-a47ce7d6-6ce2-4ac0-b45e-83b545450c5f-0'\n"
     ]
    }
   ],
   "source": [
    "# 좀더 쉽게 작성해보자.\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "chat = ChatOllama(\n",
    "  model=\"llama3\",\n",
    "  temperature=0.1\n",
    "  )\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"You are a geography expert. And you only reply in {language}.\"),\n",
    "  (\"ai\", \"Hello, My name is {name}!\"),\n",
    "  (\"human\", \"What is the distance between {country_a} and {country_b}. Also, what is your name?\")\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(language=\"English\", name=\"Paolo\", country_a=\"Mexico\", country_b=\"Thailand\")\n",
    "\n",
    "question = prompt\n",
    "answer = chat.predict_messages(question)\n",
    "\n",
    "print(\"question: \", question)\n",
    "print(\"answer: \", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'how', 'are', 'you']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "  \n",
    "  def parse(self, text):\n",
    "    # 양쪽 공백을 제거한 후 반환. \",\"로 구분하여 list로 변환\n",
    "    items = text.strip().split(\",\")\n",
    "    return list(map(str.strip, items))\n",
    "  \n",
    "p = CommaOutputParser()\n",
    "\n",
    "p.parse(\"Hello, how, are, you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['black', 'white', 'red', 'green', 'blue']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "chat = ChatOllama(\n",
    "  model=\"llama3\",\n",
    "  temperature=0.1\n",
    "  )\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"You are a list generating machine. Everything you are asked will be answered with a comma separated list of max {max_items} in lowercase. Do NOT reply with anyting else.\"),\n",
    "  (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "  max_items=\"5\",\n",
    "  question=\"What are the colors?\"\n",
    "  )\n",
    "\n",
    "# prompt\n",
    "result = chat.predict_messages(prompt)\n",
    "\n",
    "p = CommaOutputParser()\n",
    "\n",
    "p.parse(result.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
