{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3\n",
      "llama3\n",
      "a:  ğŸš€ As of now, there are eight planets officially recognized in our solar system:\n",
      "\n",
      "1. Mercury\n",
      "2. Venus\n",
      "3. Earth\n",
      "4. Mars\n",
      "5. Jupiter\n",
      "6. Saturn\n",
      "7. Uranus\n",
      "8. Neptune\n",
      "\n",
      "However, if you include dwarf planets and other smaller bodies like Pluto, Haumea, Makemake, Eris, and many others, the total number of celestial bodies in our solar system would be much higher! ğŸ¤¯\n",
      "b:  ğŸš€ According to NASA, there are currently eight planets that are officially recognized in our solar system:\n",
      "\n",
      "1. Mercury\n",
      "2. Mars\n",
      "3. Venus\n",
      "4. Earth\n",
      "5. Neptune\n",
      "6. Uranus\n",
      "7. Saturn\n",
      "8. Jupiter\n",
      "\n",
      "However, Pluto was previously considered a planet but is now classified as a dwarf planet.\n",
      "\n",
      "If we include exoplanets (planets outside our solar system), the number of known planets is over 4,000 and continues to grow as new discoveries are made! ğŸš€\n"
     ]
    }
   ],
   "source": [
    "## LLM, ChatModel ë‘ê°€ì§€ë¥¼ í˜¸ì¶œí•´ë³´ì.\n",
    "from langchain.llms.ollama import Ollama\n",
    "from langchain.chat_models import ChatOllama\n",
    "\n",
    "llm = Ollama(model=\"llama3\")\n",
    "chat = ChatOllama(model=\"llama3\")\n",
    "\n",
    "a = llm.predict(\"í–‰ì„±ì€ ëª‡ ê°œ ìˆë‚˜ìš”?\")\n",
    "b = chat.predict(\"í–‰ì„±ì€ ëª‡ ê°œ ìˆë‚˜ìš”?\")\n",
    "\n",
    "\n",
    "print(llm.model)\n",
    "print(chat.model)\n",
    "\n",
    "print(\"a: \", a)\n",
    "print(\"b: \", b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ˜Š\n",
      "\n",
      "í˜„ì¬ ìš°ë¦¬ íƒœì–‘ê³„ì—ì„œ known universeì— ìˆëŠ” í–‰ì„±ì˜ ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "* ë‚˜.writeValue(1) (Mercury)\n",
      "* Earth\n",
      "* Mars\n",
      "* Venus\n",
      "* Jupiter\n",
      "* Saturn\n",
      "* Uranus\n",
      "* Neptune\n",
      "\n",
      "ì´ ì¤‘ì—ì„œ íƒœì–‘ê³„ ë‚´ë¶€ì—ì„œëŠ” 8ê°œì˜ í–‰ì„±ì´ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì™¸ê³„í–‰ì„±ê¹Œì§€ í¬í•¨í•˜ë©´ ìˆ˜ë°±, ì²œìˆ˜ì— ì´ë¥´ëŠ” ìˆ˜ê°€ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ ë‹µë³€ì´ ë„ì›€ì´ ë˜ì—ˆë‚˜ìš”? ğŸ¤”\n"
     ]
    }
   ],
   "source": [
    "## ë©”ì‹œì§€ë“¤ì„ predictí•´ë³´ì.\n",
    "from langchain.chat_models import ChatOllama\n",
    "\n",
    "chat = ChatOllama(\n",
    "  model=\"llama3\",\n",
    "  temperature=0.1\n",
    "  )\n",
    "\n",
    "b = chat.predict(\"ì§ˆë¬¸: í–‰ì„±ì€ ëª‡ ê°œ ìˆë‚˜ìš”?, ì¡°ê±´: í•œêµ­ì–´ë¡œ ë‹µí•´ì•¼í•œë‹¤.\")\n",
    "\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
